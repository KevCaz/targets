---
execute:
  freeze: auto
---

# Local data {#data}

```{r, message = FALSE, warning = FALSE, echo = FALSE}
knitr::opts_knit$set(root.dir = fs::dir_create(tempfile()))
knitr::opts_chunk$set(collapse = TRUE, comment = "#>", eval = TRUE)
```

```{r, message = FALSE, warning = FALSE, echo = FALSE, eval = TRUE}
library(targets)
```

:::{.callout-tip}
## Performance

See the [performance chapter](#performance) for options, settings, and other choices to make storage and memory more efficient for large data workflows.
:::

During a pipeline, `targets` manages R objects in memory and writes them to files on disk. It also stores target-level metadata in a compact central text file.

## Memory

`targets` uses random access memory (RAM) while the pipeline is running. Each target loads its upstream dependencies into memory and returns an R object in memory. After a target finishes running or acts as a dependency, `tar_make()` can either keep the object in memory or discard it. In `tar_target()` or `tar_option_set()`, set `memory = "transient"` to release the target from the environment whenever possible, and set `garbage_collection = TRUE` to run garbage collection with `gc()` just before the target runs. Alternatively, set `memory = "persistent"` to keep the object in memory and reduce costly interactions with the file system. The trade-off between memory and file I/O depends on your computing platform. See the [performance chapter](#performance) for more details.

## Local data store

In addition to memory, the pipeline writes data to files on disk. `tar_make()` creates a special data folder called `_targets/` at the root of your project.

```{r, eval = FALSE}
fs::dir_tree("_targets")
_targets
├── meta
│   ├── crew
│   ├── meta
│   ├── process
│   └── progress
├── objects
│   ├── target1
│   ├── target2
│   ├── dynamic_branch_c7bcb4bd
│   ├── dynamic_branch_285fb6a9
│   └── dynamic_branch_874ca381
├── scratch # tar_make() deletes this folder after it finishes.
└── user # gittargets users can put custom files here for data version control.
```

The two most important parts are:


1. `_targets/meta/meta`: a text file with critical metadata.
2. `_targets/objects/`: a folder with the output data of each target.

Consider this pipeline:

```{r, eval = FALSE, echo = TRUE}
library(targets)
list(
  tar_target(
    name = target1,
    command = 11 + 46,
    format = "rds",
    repository = "local"
  )
)
```

`tar_make()` does the following:

1. Run the command of `target1` and observe a return value of `57`.
1. Save the value `57` to `_targets/objects/target1` using [saveRDS()](https://stat.ethz.ch/R-manual/R-devel/library/base/html/saveRDS.html).
1. Append a line to `_targets/meta/meta` containing the hash, time stamp, file size, warnings, errors, and execution time of `target1`.
1. Append a line to `_targets/meta/progress` to indicate that `target1` finished.

Remarks:

* To read the value of `target1` back into R, `tar_read(target1)` is much better than `readRDS("_targets/objects/target1")`.
* The `format` argument of `tar_target()` controls how `tar_make()` saves the return value. The default is `"rds"`, and there are more efficient formats such as `"qs"` and `"feather"`. Some of these formats require external packages. See <https://docs.ropensci.org/targets/reference/tar_target.html#storage-formats> for details.
* For efficiency, `tar_make()` does not write to `_targets/meta/meta` or `_targets/meta/progress` every single time a target completes. Instead, it waits and gathers a backlog of text lines in memory, then writes whole batches of lines at a time. This behavior risks losing metadata in the event of a crash, but it reduces costly interactions with the file system. The `seconds_meta` argument controls how often `tar_make()` writes metadata. `seconds_reporter` does the same for messages printed to the R console.

## External files

Some pipelines work with custom user-supplied files outside `_targets/`. In `targets`, the user is still responsible for reading and writing these files. However, the pipeline can track them, detect changes, and decide whether to rerun or skip the targets that the files depend on.

In a file target,

1. `tar_target()` has `format = "file"`.
2. The command returns a character vector of file paths.

Consider this pipeline: 

```{r, eval = FALSE, echo = TRUE}
# _targets.R
library(targets)

create_output <- function(file) {
  data <- read.csv(file)
  output <- head(data)
  write.csv(output, "output.csv")
  "output.csv"
}

list(
  tar_target(name = input, command = "data.csv", format = "file"),
  tar_target(name = output, command = create_output(input), format = "file")
)
```

In the dependency graph, `output` depends on `input` because the command of `output` mentions the symbol `input`.

```{r, eval = TRUE, echo = FALSE}
tar_script({
  library(targets)
  create_output <- function(file) {
    data <- read.csv(file)
    output <- head(data)
    write.csv(output, "output.csv")
    "output.csv"
  }
  list(
    tar_target(name = input, command = "data.csv", format = "file"),
    tar_target(name = output, command = create_output(input), format = "file")
  )
})
```

```{r, eval = FALSE, echo = TRUE}
tar_visnetwork()
```

```{r, eval = TRUE, echo = FALSE}
tar_visnetwork()
```

Before the pipeline first runs, `data.csv` exists, but `output.csv` does not. During `tar_make()`, the `input` target tracks `data.csv`, and the `output` target creates and tracks `output.csv`. If `data.csv` changes before the next `tar_make()`, then both `input` and `output` rerun. If something outside the pipeline changes `output.csv`, then `output` reruns.

Remarks:

* A file target can have both input and output files.
* A file target can include directory paths as well as individual file paths.
* `format = "file_fast"` is just like `format = "file"`, except that it uses file modification time stamps to check if a file is up to date. If the time stamp of the file agrees with the time stamp in the metadata, the file is considered up to date. Otherwise, targets recomputes the hash of the file to make a final determination.

## Cleaning up local internal data files

There are [multiple functions](https://docs.ropensci.org/targets/reference/index.html#section-clean) to remove or clean up target storage. Most of these functions delete internal files or records from the data store and delete objects from cloud buckets. They do not delete local external files (i.e. `tar_target(..., format = "file", repository = "local")`) because some of those files could be local input data that exists prior to `tar_make()`.

* [`tar_destroy()`](https://docs.ropensci.org/targets/reference/tar_destroy.html) is by far the most commonly used cleaning function. It removes the `_targets/` folder (or optionally a subfolder in `_targets/`) and all the cloud targets mentioned in the metadata. Use it if you intend to start the pipeline from scratch without any trace of a previous run.
* [`tar_prune()`](https://docs.ropensci.org/targets/reference/tar_prune.html) deletes the data and metadata of all the targets no longer present in your current target script file (default: `_targets.R`). This is useful if you recently worked through multiple changes to your project and are now trying to discard irrelevant data while keeping the results that still matter.
* [`tar_delete()`](https://docs.ropensci.org/targets/reference/tar_delete.html) is more selective than [`tar_destroy()`](https://docs.ropensci.org/targets/reference/tar_destroy.html) and [`tar_prune()`](https://docs.ropensci.org/targets/reference/tar_prune.html). It removes the individual data files of a given set of targets from `_targets/objects/` and cloud buckets while leaving the metadata in `_targets/meta/meta` alone. If you have a small number of data-heavy targets you need to discard to conserve storage, this function can help.
* [`tar_invalidate()`](https://docs.ropensci.org/targets/reference/tar_invalidate.html) is the complement of [`tar_delete()`](https://docs.ropensci.org/targets/reference/tar_delete.html): for the selected targets, it deletes the metadata in `_targets/meta/meta` and does not delete the return values. After invalidation, you will still be able to locate the data files with [`tar_path()`](https://docs.ropensci.org/targets/reference/tar_path.html) and manually salvage them in an emergency. However, [`tar_load()`](https://docs.ropensci.org/targets/reference/tar_load.html) and [`tar_read()`](https://docs.ropensci.org/targets/reference/tar_read.html) will not be able to read the data into R, and subsequent calls to [`tar_make()`](https://docs.ropensci.org/targets/reference/tar_make.html) will attempt to rebuild those targets.
* [`tar_meta_delete()`](https://docs.ropensci.org/targets/reference/tar_meta_delete.html) removes all the files in `_targets/meta/` that `targets` created, not just `_targets/meta/meta`, but also `_targets/meta/progress`, `_targets/meta/process`, and `_targets/meta/crew`. It also deletes the copies of these files in cloud buckets. See the [cloud storage](@cloud-storage) chapter for details.
